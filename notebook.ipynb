{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7f28e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time, base64,ssl, os, re,json5, pprint,random , math, hashlib, inspect,requests\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By                   # Locators (ID, CLASS_NAME, XPATH, etc.)\n",
    "from selenium.webdriver.support.ui import WebDriverWait       # Waits for elements to appear\n",
    "from selenium.webdriver.support import expected_conditions as EC  # Conditions like \"visible\", \"clickable\"\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "from app.utils import Helper\n",
    "from app.operation_executor import OperationExecutor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d591581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are less than three cols, skipping\n",
      "Excel saved: Orders_example_All.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_html_table(html):\n",
    "    \"\"\"Parse one HTML table into DataFrame with Date, Subject, Remarks, Link.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    table = soup.find(\"table\")\n",
    "    if not table:\n",
    "        return None\n",
    "\n",
    "    rows = []\n",
    "    for tr in table.select(\"tbody tr\"):\n",
    "        cols = tr.find_all(\"td\")\n",
    "        if len(cols) < 3:\n",
    "            print(\"There are less than three cols, skipping\")\n",
    "            continue\n",
    "\n",
    "        date = cols[0].get_text(strip=True)\n",
    "        remarks = cols[2].get_text(strip=True)\n",
    "\n",
    "        a = cols[1].find(\"a\")\n",
    "        subject = a.get_text(\" \", strip=True) if a else cols[1].get_text(strip=True)\n",
    "        link = \"\"\n",
    "        if a and a.get(\"onclick\"):\n",
    "            onclick = a[\"onclick\"]\n",
    "            if \"newwindow1\" in onclick:\n",
    "                start = onclick.find(\"'\") + 1\n",
    "                end = onclick.rfind(\"'\")\n",
    "                link = onclick[start:end]\n",
    "\n",
    "        rows.append([date, subject, remarks, link])\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"Date\", \"Subject\", \"Remarks\", \"Link\"])\n",
    "\n",
    "def clean_sheet_name(name, fallback=\"Sheet\"):\n",
    "    safe = re.sub(r'[\\[\\]\\:\\*\\?\\/\\\\]', \"_\", str(name))\n",
    "    return safe[:31] if safe else fallback\n",
    "\n",
    "def cache_to_excel(cache_file, excel_out=\"Orders_All.xlsx\"):\n",
    "    with open(cache_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    used_names = {}  # track counts per sheet name\n",
    "\n",
    "    with pd.ExcelWriter(excel_out, engine=\"xlsxwriter\") as writer:\n",
    "        for scraped in data[\"records\"][0][\"scraped_data\"]:\n",
    "            if not scraped.get(\"data_present\"):\n",
    "                continue\n",
    "\n",
    "            action = scraped.get(\"action\", \"unknown\")\n",
    "            webpage = scraped.get(\"webpage\", \"\")\n",
    "            for resp in scraped.get(\"response\", []):\n",
    "                if resp.get(\"type\") != \"table_html\":\n",
    "                    continue\n",
    "\n",
    "                df = parse_html_table(resp[\"value\"])\n",
    "                if df is None or df.empty:\n",
    "                    continue\n",
    "\n",
    "                titles = resp.get(\"title\", [])\n",
    "                base_name = clean_sheet_name(titles[-1] if titles else action)\n",
    "\n",
    "                count = used_names.get(base_name, 0) + 1\n",
    "                used_names[base_name] = count\n",
    "                sheet_name = base_name if count == 1 else clean_sheet_name(f\"{base_name}_{count}\")\n",
    "\n",
    "\n",
    "                meta_rows = [[\"Action\", action], [\"Webpage\", webpage]]\n",
    "                for i, t in enumerate(titles, start=1):\n",
    "                    meta_rows.append([f\"Header{i}\", t])\n",
    "                meta = pd.DataFrame(meta_rows, columns=[\"Meta\", \"Value\"])\n",
    "                meta.to_excel(writer, sheet_name=sheet_name, index=False, startrow=0)\n",
    "\n",
    "                df_visible = df[[\"Date\", \"Subject\", \"Remarks\",\"Link\"]]\n",
    "                startrow = len(meta) + 2\n",
    "                df_visible.to_excel(writer, sheet_name=sheet_name, index=False, startrow=startrow)\n",
    "\n",
    "                # ws = writer.sheets[sheet_name]\n",
    "                # for i, (txt, url) in enumerate(zip(df[\"Subject\"], df[\"Link\"]), start=startrow+1):\n",
    "                #     if url:\n",
    "                #         ws.write_url(i, 1, url, string=txt)\n",
    "\n",
    "    print(f\"Excel saved: {excel_out}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "path = r\"C:\\Users\\kaustubh.keny\\Projects\\JSON25\\scrape_output\\cache\\2025-09-23\\25-09-23T15-32-09_cache.json\"\n",
    "cache_to_excel(path, \"Orders_example_All.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518dfeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.sundarammutual.com/mutual-fund-commission-disclosure\")\n",
    "\n",
    "links = driver.find_elements(By.CSS_SELECTOR,\".d-block\")\n",
    "\n",
    "# print(vehicle_dashboard.get_attribute(\"outerHTML\"))\n",
    "\n",
    "for link in links:\n",
    "    print(link.get_attribute(\"outerHTML\"))\n",
    "\"pnl_trans\",\"pnl_revenue\",\"pnl_permit\",\"pnl_taxDef\"\n",
    "time.sleep(5)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79fccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO,StringIO\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": \"Mozilla/5.0\"})\n",
    "\n",
    "def fetch_rba():\n",
    "    url = \"https://www.rba.gov.au/statistics/tables/xls/f01d.xlsx\"\n",
    "    r = session.get(url, timeout=15)\n",
    "    r.raise_for_status()\n",
    "    return pd.read_excel(BytesIO(r.content))\n",
    "\n",
    "def fetch_bcra():\n",
    "    url = \"https://www.bcra.gob.ar/PublicacionesEstadisticas/Principales_variables_i.asp\"\n",
    "    r = session.get(url, timeout=15, verify=False)\n",
    "    r.raise_for_status()\n",
    "    return pd.read_html(r.text)[0]\n",
    "\n",
    "\n",
    "def fetch_banxico(token, series_ids, start, end):\n",
    "    url = f\"https://www.banxico.org.mx/SieAPIRest/service/v1/series/{','.join(series_ids)}/datos/{start}/{end}\"\n",
    "    headers = {\"Bmx-Token\": token}\n",
    "    r = session.get(url, headers=headers, timeout=15)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    records = {}\n",
    "    for s in data['bmx']['series']:\n",
    "        sid = s['idSerie']\n",
    "        rec = {d['fecha']: d['dato'] for d in s['datos']}\n",
    "        records[sid] = rec\n",
    "    df = pd.DataFrame.from_dict(records, orient=\"index\")\n",
    "    df.columns = pd.to_datetime(df.columns, dayfirst=True)\n",
    "    return df.sort_index(axis=1)\n",
    "\n",
    "\n",
    "def fetch_boc(series_ids, start, end):\n",
    "    url = f\"https://www.bankofcanada.ca/valet/observations/{','.join(series_ids)}/json?start_date={start}&end_date={end}\"\n",
    "    r = session.get(url, timeout=15)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    records = {}\n",
    "    for row in data[\"observations\"]:\n",
    "        date = row[\"d\"]\n",
    "        for sid in series_ids:\n",
    "            records.setdefault(sid, {})[date] = row.get(sid, {}).get(\"v\")\n",
    "    df = pd.DataFrame.from_dict(records, orient=\"index\")\n",
    "    df.columns = pd.to_datetime(df.columns)\n",
    "    return df.sort_index(axis=1)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(\"central_banks.xlsx\") as writer:\n",
    "    token = \"1846d489e18513d4306b70e257a21edb56e82325de0139af91dd2176975029bf\"\n",
    "    fetch_banxico(token, [\"SF61745\",\"SF331451\",\"SF43783\",\"SF43878\",\"SF111916\"], \"2025-09-18\", \"2025-09-22\")\\\n",
    "        .to_excel(writer, sheet_name=\"Banxico\")\n",
    "    fetch_boc([\"V39079\",\"CL.CDN.MOST.1DL\",\"V39078\",\"V80691310\",\"V122530\"], \"2025-09-18\", \"2025-09-23\")\\\n",
    "        .to_excel(writer, sheet_name=\"BoC\")\n",
    "    fetch_rba().to_excel(writer, sheet_name=\"RBA\", index=False)\n",
    "    fetch_bcra().to_excel(writer, sheet_name=\"BCRA\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27b9213b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title',\n",
       " 'Cash Rate Target',\n",
       " 'Change in the Cash Rate Target ',\n",
       " 'Interbank Overnight Cash Rate',\n",
       " 'Highest Interbank Overnight Cash Rate',\n",
       " 'Lowest Interbank Overnight Cash Rate',\n",
       " 'Volume of Cash Market Transactions',\n",
       " 'Number of Cash Market Transactions',\n",
       " 'Total Return Index',\n",
       " 'EOD 1-month BABs/NCDs',\n",
       " 'EOD 3-month BABs/NCDs',\n",
       " 'EOD 6-month BABs/NCDs',\n",
       " '1-month OIS',\n",
       " '3-month OIS',\n",
       " '6-month OIS',\n",
       " '1-month Treasury Note',\n",
       " '3- month Treasury Note',\n",
       " '6- month Treasury Note']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Title\tCash Rate Target\tChange in the Cash Rate Target \tInterbank Overnight Cash Rate\tHighest Interbank Overnight Cash Rate\tLowest Interbank Overnight Cash Rate\tVolume of Cash Market Transactions\tNumber of Cash Market Transactions\tTotal Return Index\tEOD 1-month BABs/NCDs\tEOD 3-month BABs/NCDs\tEOD 6-month BABs/NCDs\t1-month OIS\t3-month OIS\t6-month OIS\t1-month Treasury Note\t3- month Treasury Note\t6- month Treasury Note\".split(\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e62817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.operation_executor import OperationExecutor\n",
    "from app.utils import Helper\n",
    "path = r\"C:\\Users\\rando\\Office Projects\\outputs\\scrape_output\\cache\\2025-09-23\\25-09-23T22-31-06_cache.json\"\n",
    "data = Helper.load_json(path)\n",
    "OperationExecutor.generate_cache_doc_report(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b827023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO,StringIO\n",
    "from datetime import datetime\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": \"Mozilla/5.0\"})\n",
    "\n",
    "def fetch_rba(): \n",
    "    url = \"https://www.rba.gov.au/statistics/tables/xls/f01d.xlsx\" \n",
    "    r = session.get(url, timeout=15) \n",
    "    r.raise_for_status() \n",
    "    df = pd.read_excel(BytesIO(r.content)) \n",
    "    df.columns = df.iloc[1, :]\n",
    "    df = df.iloc[-5:, :].T.reset_index()\n",
    "    df.columns = df.iloc[0, :]\n",
    "    df = df.drop(df.index[0])\n",
    "    df.columns = [(lambda c: pd.to_datetime(c, errors=\"ignore\"))(c) for c in df.columns]\n",
    "    df.columns = [c.strftime(\"%m-%d-%Y\") if isinstance(c, pd.Timestamp) else c for c in df.columns]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fetch_bcra():\n",
    "    url = \"https://www.bcra.gob.ar/PublicacionesEstadisticas/Principales_variables_i.asp\"\n",
    "    r = session.get(url, timeout=15, verify=False)\n",
    "    r.raise_for_status()\n",
    "    df = pd.read_html(r.text)[0]\n",
    "    \n",
    "    today = datetime.today().strftime(\"%d-%m-%Y\")\n",
    "    date_range = pd.date_range(end=today, periods=5)   # datetime index\n",
    "\n",
    "    df.columns = [\"Header\",\"Date\",\"Value\"]\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "    reshaped = (df.pivot_table(index=\"Header\", columns=\"Date\", values=\"Value\", aggfunc=\"first\"))\n",
    "    reshaped = reshaped.reindex(columns=date_range)\n",
    "    reshaped.columns = [d.strftime(\"%m-%d-%Y\") for d in reshaped.columns]\n",
    "    reshaped = reshaped.reset_index()\n",
    "    return reshaped\n",
    "\n",
    "def fetch_banxico(token, series_ids, start, end): \n",
    "    #mapper\n",
    "    series_map = {\n",
    "        \"SF61745\": \"Target rate 1/\",\n",
    "        \"SF331451\": \"Overnight TIIE funding rate 2/\",\n",
    "        \"SF43783\": \"28 day TIIE 3/\",\n",
    "        \"SF43878\": \"91 day TIIE 3/\",\n",
    "        \"SF111916\": \"182 day TIIE 3/\"\n",
    "    }\n",
    "    \n",
    "    #api call\n",
    "    url = f\"https://www.banxico.org.mx/SieAPIRest/service/v1/series/{','.join(series_ids)}/datos/{start}/{end}\"\n",
    "    headers = {\"Bmx-Token\": token}\n",
    "    r = session.get(url, headers=headers, timeout=15)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    records = {}\n",
    "    for s in data['bmx']['series']:\n",
    "        sid = s['idSerie']\n",
    "        rec = {d['fecha']: d['dato'] for d in s['datos']}\n",
    "        records[sid] = rec\n",
    "    df = pd.DataFrame.from_dict(records, orient=\"index\")\n",
    "    df.columns = pd.to_datetime(df.columns, dayfirst=True)\n",
    "    \n",
    "    df.index = df.index.map(lambda x: series_map.get(x, x))\n",
    "    # print(df)\n",
    "    df.columns = [d.strftime(\"%m-%d-%Y\") for d in df.columns]\n",
    "    \n",
    "    return df.sort_index(axis=1)\n",
    "\n",
    "def fetch_boc(series_ids, start, end):\n",
    "    series_map = {\n",
    "        \"V39079\": \"Target for the overnight rate\",\n",
    "        \"CL.CDN.MOST.1DL\": \"Overnight money market financing rate1\",\n",
    "        \"V39078\": \"Bank rate - Daily\",\n",
    "        \"V80691310\": \"Bank rate - Weekly\",\n",
    "        \"V122530\": \"Bank rate - Monthly\"\n",
    "    }\n",
    "    \n",
    "    url = f\"https://www.bankofcanada.ca/valet/observations/{','.join(series_ids)}/json?start_date={start}&end_date={end}\"\n",
    "    r = session.get(url, timeout=15)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    records = {}\n",
    "    for row in data[\"observations\"]:\n",
    "        date = row[\"d\"]\n",
    "        for sid in series_ids:\n",
    "            records.setdefault(sid, {})[date] = row.get(sid, {}).get(\"v\")\n",
    "\n",
    "    df = pd.DataFrame.from_dict(records, orient=\"index\")\n",
    "    # make sure column labels are datetime\n",
    "    df.columns = pd.to_datetime(df.columns)\n",
    "    full_range = pd.date_range(start=start, end=end, freq=\"D\")\n",
    "    df = df.reindex(columns=full_range)\n",
    "    df.columns = [d.strftime(\"%m-%d-%Y\") for d in df.columns]\n",
    "    df.index = df.index.map(lambda x: series_map.get(x, x))\n",
    "\n",
    "    return df.sort_index(axis=1)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(\"central_banks_1.xlsx\") as writer:\n",
    "    token = \"1846d489e18513d4306b70e257a21edb56e82325de0139af91dd2176975029bf\"\n",
    "    fetch_banxico(token, [\"SF61745\",\"SF331451\",\"SF43783\",\"SF43878\",\"SF111916\"], \"2025-09-25\", \"2025-09-29\")\\\n",
    "        .to_excel(writer, sheet_name=\"Banxico\")\n",
    "    fetch_boc([\"V39079\",\"CL.CDN.MOST.1DL\",\"V39078\",\"V80691310\",\"V122530\"], \"2025-09-25\", \"2025-09-29\")\\\n",
    "        .to_excel(writer, sheet_name=\"BoC\")\n",
    "    fetch_rba().to_excel(writer, sheet_name=\"RBA\", index = False)\n",
    "    fetch_bcra().to_excel(writer, sheet_name=\"BCRA\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f28dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": \"Mozilla/5.0\"})\n",
    "\n",
    "\n",
    "# ---- Shared Pandas Helpers ----\n",
    "def normalize_columns_to_dates(df):\n",
    "    \"\"\"Convert datetime-like columns to mm-dd-YYYY strings.\"\"\"\n",
    "    df.columns = [\n",
    "        c.strftime(\"%m-%d-%Y\") if isinstance(c, pd.Timestamp) else c\n",
    "        for c in df.columns\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "\n",
    "def ensure_full_date_range(df, start, end):\n",
    "    \"\"\"Ensure dataframe has full date coverage, fill missing dates with NaN.\"\"\"\n",
    "    full_range = pd.date_range(start=start, end=end, freq=\"D\")\n",
    "    df = df.reindex(columns=full_range)\n",
    "    return normalize_columns_to_dates(df)\n",
    "\n",
    "# ---- Fetchers ----\n",
    "def fetch_rba(cfg, start=None, end=None):\n",
    "    r = session.get(cfg[\"url\"], timeout=15)\n",
    "    r.raise_for_status()\n",
    "    df = pd.read_excel(BytesIO(r.content))\n",
    "\n",
    "    df.columns = df.iloc[1, :]\n",
    "    df = df.iloc[-5:, :].T.reset_index()\n",
    "    df.columns = df.iloc[0, :]\n",
    "    df = df.drop(df.index[0])\n",
    "\n",
    "    return normalize_columns_to_dates(df)\n",
    "\n",
    "\n",
    "def fetch_bcra(cfg, start=None, end=None):\n",
    "    r = session.get(cfg[\"url\"], timeout=15, verify=False)\n",
    "    r.raise_for_status()\n",
    "    df = pd.read_html(r.text)[0]\n",
    "\n",
    "    today = datetime.today()\n",
    "    date_range = pd.date_range(end=today, periods=5)   # last 5 days\n",
    "\n",
    "    df.columns = [\"Header\", \"Date\", \"Value\"]\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "    reshaped = df.pivot_table(index=\"Header\", columns=\"Date\", values=\"Value\", aggfunc=\"first\")\n",
    "    reshaped = reshaped.reindex(columns=date_range)\n",
    "    reshaped = normalize_columns_to_dates(reshaped)\n",
    "    return reshaped.reset_index()\n",
    "\n",
    "\n",
    "def fetch_banxico(cfg, start, end):\n",
    "    url = f\"{cfg['url']}/{','.join(cfg['series_ids'])}/datos/{start}/{end}\"\n",
    "    r = session.get(url, headers=cfg[\"headers\"], timeout=15)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    records = {}\n",
    "    for s in data['bmx']['series']:\n",
    "        sid = s['idSerie']\n",
    "        rec = {d['fecha']: d['dato'] for d in s['datos']}\n",
    "        records[sid] = rec\n",
    "\n",
    "    df = pd.DataFrame.from_dict(records, orient=\"index\")\n",
    "    df.columns = pd.to_datetime(df.columns, dayfirst=True)\n",
    "    df.index = df.index.map(lambda x: cfg[\"series_map\"].get(x, x))\n",
    "\n",
    "    return normalize_columns_to_dates(df.sort_index(axis=1))\n",
    "\n",
    "\n",
    "def fetch_boc(cfg, start, end):\n",
    "    url = f\"{cfg['url']}/{','.join(cfg['series_ids'])}/json?start_date={start}&end_date={end}\"\n",
    "    r = session.get(url, timeout=15)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    records = {}\n",
    "    for row in data[\"observations\"]:\n",
    "        date = row[\"d\"]\n",
    "        for sid in cfg[\"series_ids\"]:\n",
    "            records.setdefault(sid, {})[date] = row.get(sid, {}).get(\"v\")\n",
    "\n",
    "    df = pd.DataFrame.from_dict(records, orient=\"index\")\n",
    "    df.columns = pd.to_datetime(df.columns)\n",
    "    df = ensure_full_date_range(df, start, end)\n",
    "    df.index = df.index.map(lambda x: cfg[\"series_map\"].get(x, x))\n",
    "\n",
    "    return df.sort_index(axis=1)\n",
    "\n",
    "CONFIG = {\n",
    "    \"Banxico\": {\n",
    "        \"fetcher\": fetch_banxico,\n",
    "        \"url\": \"https://www.banxico.org.mx/SieAPIRest/service/v1/series\",\n",
    "        \"headers\": {\"Bmx-Token\": \"1846d489e18513d4306b70e257a21edb56e82325de0139af91dd2176975029bf\"},\n",
    "        \"series_ids\": [\"SF61745\",\"SF331451\",\"SF43783\",\"SF43878\",\"SF111916\"],\n",
    "        \"series_map\": {\n",
    "            \"SF61745\": \"Target rate 1/\",\n",
    "            \"SF331451\": \"Overnight TIIE funding rate 2/\",\n",
    "            \"SF43783\": \"28 day TIIE 3/\",\n",
    "            \"SF43878\": \"91 day TIIE 3/\",\n",
    "            \"SF111916\": \"182 day TIIE 3/\"\n",
    "        }\n",
    "    },\n",
    "    \"BoC\": {\n",
    "        \"fetcher\": fetch_boc,\n",
    "        \"url\": \"https://www.bankofcanada.ca/valet/observations\",\n",
    "        \"series_ids\": [\"V39079\",\"CL.CDN.MOST.1DL\",\"V39078\",\"V80691310\",\"V122530\"],\n",
    "        \"series_map\": {\n",
    "            \"V39079\": \"Target for the overnight rate\",\n",
    "            \"CL.CDN.MOST.1DL\": \"Overnight money market financing rate1\",\n",
    "            \"V39078\": \"Bank rate - Daily\",\n",
    "            \"V80691310\": \"Bank rate - Weekly\",\n",
    "            \"V122530\": \"Bank rate - Monthly\"\n",
    "        }\n",
    "    },\n",
    "    \"RBA\": {\n",
    "        \"fetcher\": fetch_rba,\n",
    "        \"url\": \"https://www.rba.gov.au/statistics/tables/xls/f01d.xlsx\"\n",
    "    },\n",
    "    \"BCRA\": {\n",
    "        \"fetcher\": fetch_bcra,\n",
    "        \"url\": \"https://www.bcra.gob.ar/PublicacionesEstadisticas/Principales_variables_i.asp\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def run_pipeline(days=5, outfile=\"central_banks_config.xlsx\"):\n",
    "    end = datetime.today()\n",
    "    start = end - timedelta(days=days)\n",
    "\n",
    "    with pd.ExcelWriter(outfile) as writer:\n",
    "        for name, cfg in CONFIG.items():\n",
    "            fetcher = cfg[\"fetcher\"]\n",
    "\n",
    "            if name in [\"Banxico\", \"BoC\"]:\n",
    "                df = fetcher(cfg, start.strftime(\"%Y-%m-%d\"), end.strftime(\"%Y-%m-%d\"))\n",
    "            else:\n",
    "                df = fetcher(cfg, start, end)\n",
    "\n",
    "            df.to_excel(writer, sheet_name=name, index=not name in [\"RBA\", \"BCRA\"])\n",
    "    print(f\"✅ Data saved to {outfile}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline(days=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb0a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75407c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eff7757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Processing Bank of Baroda\n"
     ]
    }
   ],
   "source": [
    "from app.operation_executor import OperationExecutor\n",
    "from app.utils import Helper\n",
    "from urllib.parse import urljoin\n",
    "import os\n",
    "ops = OperationExecutor()\n",
    "path = r\"C:\\Users\\kaustubh.keny\\Projects\\JSON25\\scrape_output\\cache\\2025-09-26\\25-09-26T15-44-07_cache.json\"\n",
    "# path = r\"25-09-08T18-33-09_cache.json5\"\n",
    "path = r\"C:\\Users\\kaustubh.keny\\Projects\\JSON25\\scrape_output\\cache\\2025-09-26\\25-09-26T15-39-53_cache.json\"\n",
    "\n",
    "    \n",
    "root_file = os.path.basename(path).split(\"_\")[0]\n",
    "function_to_execute = {\n",
    "\"primary\":[[\"normalize_df\",\"value\",\"norm_table\",\"table_html\"],[\"sha1\",\"value\",\"SHA_ONE\",\"pdf\"]],\n",
    "\"secondary\":[[\"sha1\",\"norm_table\",\"SHA_ONE\"]],\n",
    "}\n",
    "try:\n",
    "    data = Helper.load_json(path, typ=\"json5\")\n",
    "    processed_data = ops.runner(data,function_to_execute)\n",
    "    Helper.save_json(processed_data,f\"{root_file}_process.json\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError in Processing.. Skipping, {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945fdec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Despoit_Rate_Report.xlsx'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app.operation_executor import OperationExecutor\n",
    "from app.utils import Helper\n",
    "ops = OperationExecutor()\n",
    "\n",
    "v1 = r\"25-09-26T15-44-07_process.json\"\n",
    "v2 = r\"25-09-26T15-39-53_process.json\"\n",
    "yesterday = Helper.load_json(v2)\n",
    "today = Helper.load_json(v1)\n",
    "\n",
    "result = ops.process_comparison(yesterday,today,key=\"SHA_ONE\")\n",
    "Helper.save_json(result, \"compare-080925.json\")\n",
    "\n",
    "ops.generate_sorted_excel_report(result,output_path=\"Despoit_Rate_Report.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a26a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Despoit_Rate_Report.xlsx'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app.operation_executor import OperationExecutor\n",
    "from app.utils import Helper\n",
    "ops = OperationExecutor()\n",
    "\n",
    "path = r\"C:\\Users\\kaustubh.keny\\Projects\\JSON25\\scrape_output\\cache\\1109_1009_compare\\compare-080925.json\"\n",
    "result = Helper.load_json(path)\n",
    "ops.generate_sorted_excel_report(result,output_path=\"Despoit_Rate_Report.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
