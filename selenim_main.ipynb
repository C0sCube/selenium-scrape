{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b7f28e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time, base64,ssl, os, re,json5, pprint,random , math, hashlib, inspect,requests\n",
    "from selenium import webdriver# Controls the browser\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By                   # Locators (ID, CLASS_NAME, XPATH, etc.)\n",
    "from selenium.webdriver.support.ui import WebDriverWait       # Waits for elements to appear\n",
    "from selenium.webdriver.support import expected_conditions as EC  # Conditions like \"visible\", \"clickable\"\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "from app.utils import Helper\n",
    "from app.operation_executor import OperationExecutor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d591581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are less than three cols, skipping\n",
      "Excel saved: Orders_All.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_html_table(html):\n",
    "    \"\"\"Parse one HTML table into DataFrame with Date, Subject, Remarks, Link.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    table = soup.find(\"table\")\n",
    "    if not table:\n",
    "        return None\n",
    "\n",
    "    rows = []\n",
    "    for tr in table.select(\"tbody tr\"):\n",
    "        cols = tr.find_all(\"td\")\n",
    "        if len(cols) < 3:\n",
    "            print(\"There are less than three cols, skipping\")\n",
    "            continue\n",
    "\n",
    "        date = cols[0].get_text(strip=True)\n",
    "        remarks = cols[2].get_text(strip=True)\n",
    "\n",
    "        a = cols[1].find(\"a\")\n",
    "        subject = a.get_text(\" \", strip=True) if a else cols[1].get_text(strip=True)\n",
    "        link = \"\"\n",
    "        if a and a.get(\"onclick\"):\n",
    "            onclick = a[\"onclick\"]\n",
    "            if \"newwindow1\" in onclick:\n",
    "                start = onclick.find(\"'\") + 1\n",
    "                end = onclick.rfind(\"'\")\n",
    "                link = onclick[start:end]\n",
    "\n",
    "        rows.append([date, subject, remarks, link])\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"Date\", \"Subject\", \"Remarks\", \"Link\"])\n",
    "\n",
    "def clean_sheet_name(name, fallback=\"Sheet\"):\n",
    "    safe = re.sub(r'[\\[\\]\\:\\*\\?\\/\\\\]', \"_\", str(name))\n",
    "    return safe[:31] if safe else fallback\n",
    "\n",
    "def cache_to_excel(cache_file, excel_out=\"Orders_All.xlsx\"):\n",
    "    with open(cache_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    used_names = {}  # track counts per sheet name\n",
    "\n",
    "    with pd.ExcelWriter(excel_out, engine=\"xlsxwriter\") as writer:\n",
    "        for scraped in data[\"records\"][0][\"scraped_data\"]:\n",
    "            if not scraped.get(\"data_present\"):\n",
    "                continue\n",
    "\n",
    "            action = scraped.get(\"action\", \"unknown\")\n",
    "            webpage = scraped.get(\"webpage\", \"\")\n",
    "            for resp in scraped.get(\"response\", []):\n",
    "                if resp.get(\"type\") != \"table_html\":\n",
    "                    continue\n",
    "\n",
    "                df = parse_html_table(resp[\"value\"])\n",
    "                if df is None or df.empty:\n",
    "                    continue\n",
    "\n",
    "                titles = resp.get(\"title\", [])\n",
    "                base_name = clean_sheet_name(titles[-1] if titles else action)\n",
    "\n",
    "                count = used_names.get(base_name, 0) + 1\n",
    "                used_names[base_name] = count\n",
    "                sheet_name = base_name if count == 1 else clean_sheet_name(f\"{base_name}_{count}\")\n",
    "\n",
    "\n",
    "                meta_rows = [[\"Action\", action], [\"Webpage\", webpage]]\n",
    "                for i, t in enumerate(titles, start=1):\n",
    "                    meta_rows.append([f\"Header{i}\", t])\n",
    "                meta = pd.DataFrame(meta_rows, columns=[\"Meta\", \"Value\"])\n",
    "                meta.to_excel(writer, sheet_name=sheet_name, index=False, startrow=0)\n",
    "\n",
    "                df_visible = df[[\"Date\", \"Subject\", \"Remarks\"]]\n",
    "                startrow = len(meta) + 2\n",
    "                df_visible.to_excel(writer, sheet_name=sheet_name, index=False, startrow=startrow)\n",
    "\n",
    "                ws = writer.sheets[sheet_name]\n",
    "                for i, (txt, url) in enumerate(zip(df[\"Subject\"], df[\"Link\"]), start=startrow+1):\n",
    "                    if url:\n",
    "                        ws.write_url(i, 1, url, string=txt)\n",
    "\n",
    "    print(f\"Excel saved: {excel_out}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "path = r\"C:\\Users\\rando\\Office Projects\\outputs\\scrape_output\\cache\\2025-09-22\\25-09-22T21-53-05_cache.json\"\n",
    "cache_to_excel(path, \"Orders_All.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed911e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=25\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=26\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=27\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=28\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=45\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=46\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=29\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=30\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=49\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=31\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=32\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=33\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=47\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=34\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=35\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=48\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=36\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=39\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=37\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=38\",\n",
    "    \"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=40\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754dd0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Principal Bench, New Delhi', 'New Delhi Bench - II', 'New Delhi Bench - III', 'New Delhi Bench - IV', 'New Delhi Bench - V', 'New Delhi Bench - VI', 'Ahmedabad Bench', 'Allahabad Bench', 'Amravati Bench', 'Bengaluru Bench', 'Chandigarh Bench', 'Chennai Bench', 'Cuttack Bench', 'Guwahati Bench', 'Hyderabad Bench', 'Indore Bench', 'Jaipur Bench', 'Kochi Bench', 'Kolkata Bench', 'Mumbai Bench', 'Others']\n"
     ]
    }
   ],
   "source": [
    "Hello= {\n",
    "    \"25\": \"Principal Bench, New Delhi\",\n",
    "    \"26\": \"New Delhi Bench - II\",\n",
    "    \"27\": \"New Delhi Bench - III\",\n",
    "    \"28\": \"New Delhi Bench - IV\",\n",
    "    \"45\": \"New Delhi Bench - V\",\n",
    "    \"46\": \"New Delhi Bench - VI\",\n",
    "    \"29\": \"Ahmedabad Bench\",\n",
    "    \"30\": \"Allahabad Bench\",\n",
    "    \"49\": \"Amravati Bench\",\n",
    "    \"31\": \"Bengaluru Bench\",\n",
    "    \"32\": \"Chandigarh Bench\",\n",
    "    \"33\": \"Chennai Bench\",\n",
    "    \"47\": \"Cuttack Bench\",\n",
    "    \"34\": \"Guwahati Bench\",\n",
    "    \"35\": \"Hyderabad Bench\",\n",
    "    \"48\": \"Indore Bench\",\n",
    "    \"36\": \"Jaipur Bench\",\n",
    "    \"39\": \"Kochi Bench\",\n",
    "    \"37\": \"Kolkata Bench\",\n",
    "    \"38\": \"Mumbai Bench\",\n",
    "    \"40\": \"Others\"\n",
    "}\n",
    "\n",
    "from datetime import datetime\n",
    "date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "# print(date)\n",
    "\n",
    "cities = []\n",
    "for code, city in Hello.items():\n",
    "    website_path = f\"https://ibbi.gov.in/en/orders/nclt?title=&date={date}&nclt={code}\"\n",
    "    cities.append(city)\n",
    "    \n",
    "print(cities)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be40637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] The chromedriver version (139.0.7258.138) detected in PATH at C:\\Users\\rando\\chromedriver-win64\\chromedriver.exe might not be compatible with the detected chrome version (140.0.7339.128); currently, chromedriver 140.0.7339.185 is recommended for chrome 140.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: title, Type: text, Value: \n",
      "Name: date, Type: text, Value: 2025-09-22\n",
      "Name: , Type: submit, Value: Apply\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://ibbi.gov.in/en/orders/nclt?title=&date=2025-09-22&nclt=25\")\n",
    "\n",
    "# all input fields inside the form\n",
    "inputs = driver.find_elements(By.CSS_SELECTOR, \"#myFormId input\")\n",
    "\n",
    "for inp in inputs:\n",
    "    name = inp.get_attribute(\"name\")\n",
    "    itype = inp.get_attribute(\"type\")\n",
    "    value = inp.get_attribute(\"value\")\n",
    "\n",
    "    print(f\"Name: {name}, Type: {itype}, Value: {value}\")\n",
    "\n",
    "time.sleep(5)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0c8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e62817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.operation_executor import OperationExecutor\n",
    "from app.utils import Helper\n",
    "path = r\"C:\\Users\\kaustubh.keny\\Projects\\JSON25\\scrape_output\\cache\\2025-09-10\\25-09-10T16-42-02_cache.json\"\n",
    "data = Helper.load_json(path)\n",
    "OperationExecutor.generate_cache_doc_report(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.operation_executor import OperationExecutor\n",
    "from app.utils import Helper\n",
    "from urllib.parse import urljoin\n",
    "import os\n",
    "ops = OperationExecutor()\n",
    "path = r\"25-09-10T16-42-02_cache.json\"\n",
    "# path = r\"25-09-08T18-33-09_cache.json5\"\n",
    "\n",
    "    \n",
    "root_file = os.path.basename(path).split(\"_\")[0]\n",
    "function_to_execute = {\n",
    "\"primary\":[[\"normalize_df\",\"value\",\"norm_table\",\"table_html\"],[\"sha1\",\"value\",\"SHA_ONE\",\"pdf\"]],\n",
    "\"secondary\":[[\"sha1\",\"norm_table\",\"SHA_ONE\"]],\n",
    "}\n",
    "try:\n",
    "    data = Helper.load_json(path, typ=\"json5\")\n",
    "    processed_data = ops.runner(data,function_to_execute)\n",
    "    Helper.save_json(processed_data,f\"{root_file}_process.json\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError in Processing.. Skipping, {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945fdec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.operation_executor import OperationExecutor\n",
    "from app.utils import Helper\n",
    "ops = OperationExecutor()\n",
    "yesterday = Helper.load_json(\"25-09-09T15-14-38_process.json\")\n",
    "today = Helper.load_json(\"25-09-10T16-42-02_process.json\")\n",
    "\n",
    "result = ops.process_comparison(yesterday,today,key=\"SHA_ONE\")\n",
    "Helper.save_json(result, \"compare-080925.json\")\n",
    "\n",
    "ops.generate_sorted_excel_report(result,output_path=\"Despoit_Rate_Report.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a26a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Despoit_Rate_Report.xlsx'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app.operation_executor import OperationExecutor\n",
    "from app.utils import Helper\n",
    "ops = OperationExecutor()\n",
    "\n",
    "path = r\"C:\\Users\\kaustubh.keny\\Projects\\JSON25\\scrape_output\\cache\\1109_1009_compare\\compare-080925.json\"\n",
    "result = Helper.load_json(path)\n",
    "ops.generate_sorted_excel_report(result,output_path=\"Despoit_Rate_Report.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
