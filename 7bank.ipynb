{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f12a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": \"Mozilla/5.0\"})\n",
    "\n",
    "\n",
    "# ---- Shared Pandas Helpers ----\n",
    "def normalize_columns_to_dates(df):\n",
    "    \"\"\"Convert datetime-like columns to mm-dd-YYYY strings.\"\"\"\n",
    "    df.columns = [\n",
    "        c.strftime(\"%m-%d-%Y\") if isinstance(c, pd.Timestamp) else c\n",
    "        for c in df.columns\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "\n",
    "def ensure_full_date_range(df, start, end):\n",
    "    \"\"\"Ensure dataframe has full date coverage, fill missing dates with NaN.\"\"\"\n",
    "    full_range = pd.date_range(start=start, end=end, freq=\"D\")\n",
    "    df = df.reindex(columns=full_range)\n",
    "    return normalize_columns_to_dates(df)\n",
    "\n",
    "# ---- Fetchers ----\n",
    "def fetch_rba(cfg, start=None, end=None):\n",
    "    r = session.get(cfg[\"url\"], timeout=15)\n",
    "    r.raise_for_status()\n",
    "    df = pd.read_excel(BytesIO(r.content))\n",
    "\n",
    "    df.columns = df.iloc[1, :]\n",
    "    df = df.iloc[-5:, :].T.reset_index()\n",
    "    df.columns = df.iloc[0, :]\n",
    "    df = df.drop(df.index[0])\n",
    "\n",
    "    return normalize_columns_to_dates(df)\n",
    "\n",
    "def fetch_bcra(cfg, start=None, end=None):\n",
    "    r = session.get(cfg[\"url\"], timeout=15, verify=False)\n",
    "    r.raise_for_status()\n",
    "    df = pd.read_html(r.text)[0]\n",
    "\n",
    "    today = datetime.today()\n",
    "    date_range = pd.date_range(end=today, periods=5)   # last 5 days\n",
    "\n",
    "    df.columns = [\"Header\", \"Date\", \"Value\"]\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "    reshaped = df.pivot_table(index=\"Header\", columns=\"Date\", values=\"Value\", aggfunc=\"first\")\n",
    "    reshaped = reshaped.reindex(columns=date_range)\n",
    "    reshaped = normalize_columns_to_dates(reshaped)\n",
    "    return reshaped.reset_index()\n",
    "\n",
    "def fetch_banxico(cfg, start, end):\n",
    "    url = f\"{cfg['url']}/{','.join(cfg['series_ids'])}/datos/{start}/{end}\"\n",
    "    r = session.get(url, headers=cfg[\"headers\"], timeout=15)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    records = {}\n",
    "    for s in data['bmx']['series']:\n",
    "        sid = s['idSerie']\n",
    "        rec = {d['fecha']: d['dato'] for d in s['datos']}\n",
    "        records[sid] = rec\n",
    "\n",
    "    df = pd.DataFrame.from_dict(records, orient=\"index\")\n",
    "    df.columns = pd.to_datetime(df.columns, dayfirst=True)\n",
    "    df.index = df.index.map(lambda x: cfg[\"series_map\"].get(x, x))\n",
    "\n",
    "    return normalize_columns_to_dates(df.sort_index(axis=1))\n",
    "\n",
    "def fetch_boc(cfg, start, end):\n",
    "    url = f\"{cfg['url']}/{','.join(cfg['series_ids'])}/json?start_date={start}&end_date={end}\"\n",
    "    r = session.get(url, timeout=15)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    records = {}\n",
    "    for row in data[\"observations\"]:\n",
    "        date = row[\"d\"]\n",
    "        for sid in cfg[\"series_ids\"]:\n",
    "            records.setdefault(sid, {})[date] = row.get(sid, {}).get(\"v\")\n",
    "\n",
    "    df = pd.DataFrame.from_dict(records, orient=\"index\")\n",
    "    df.columns = pd.to_datetime(df.columns)\n",
    "    df = ensure_full_date_range(df, start, end)\n",
    "    df.index = df.index.map(lambda x: cfg[\"series_map\"].get(x, x))\n",
    "\n",
    "    return df.sort_index(axis=1)\n",
    "\n",
    "def fetch_boj(cfg, start, end):\n",
    "    dates = pd.date_range(start=datetime.strptime(start, \"%y%m%d\"), end=datetime.strptime(end, \"%y%m%d\"))\n",
    "    records = {}\n",
    "\n",
    "    for date in dates:\n",
    "        url = f\"{cfg['url']}/md{date.strftime('%y%m%d')}.htm\"\n",
    "        try:\n",
    "            r = session.get(url, timeout=15)\n",
    "            if r.status_code != 200:continue\n",
    "        except Exception:continue\n",
    "\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        for li in soup.find_all(\"li\"):\n",
    "            text = li.get_text(strip=True)\n",
    "            text = re.sub(r\"[\\[\\%]+\",\"\",text,re.IGNORECASE)\n",
    "            parts = text.split(\"]\")\n",
    "            if len(parts) < 2:continue\n",
    "            key,val = parts\n",
    "            # print(f\"{key}:{val}\")\n",
    "            series_name = f\"Call Rate {key}\"\n",
    "            records.setdefault(series_name, {})[date] = val\n",
    "\n",
    "    out = pd.DataFrame.from_dict(records, orient=\"index\")\n",
    "    out = out.reindex(columns=dates)\n",
    "    return normalize_columns_to_dates(out)\n",
    "\n",
    "def fetch_nyfed(cfg, start, end):\n",
    "    url = (\n",
    "        f\"{cfg['url']}?startDt={start}&endDt={end}\"\n",
    "        f\"&sort={cfg['headers']['sort']}\"\n",
    "        f\"&productCode={cfg['headers']['productCode']}\"\n",
    "        f\"&eventCodes={cfg['headers']['eventCodes']}\"\n",
    "        f\"&format={cfg['headers']['format']}\"\n",
    "    )\n",
    "    r = session.get(url, timeout=15)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    if cfg[\"headers\"][\"format\"] == \"csv\":\n",
    "        df = pd.read_csv(BytesIO(r.content))\n",
    "    else:\n",
    "        df = pd.read_excel(BytesIO(r.content))\n",
    "\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def fetch_cboe(cfg, start=None, end=None, days=5):\n",
    "    r = session.get(cfg[\"url\"], timeout=15, verify=False)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    df = pd.read_csv(BytesIO(r.content))\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], errors=\"coerce\")\n",
    "    df = df.iloc[-days:, :]\n",
    "    start_dt = pd.to_datetime(start)\n",
    "    end_dt = pd.to_datetime(end)\n",
    "    full_range = pd.date_range(start=start_dt, end=end_dt, freq=\"D\")\n",
    "    df = df.set_index(\"DATE\").reindex(full_range)\n",
    "    wide = pd.DataFrame([df[\"OVX\"].tolist()], index=[\"OVX Index\"], columns=full_range)\n",
    "    return normalize_columns_to_dates(wide)\n",
    "\n",
    "CONFIG = {\n",
    "    \"Banxico\": {\n",
    "        \"fetcher\": fetch_banxico,\n",
    "        \"url\": \"https://www.banxico.org.mx/SieAPIRest/service/v1/series\",\n",
    "        \"headers\": {\n",
    "            \"Bmx-Token\": \"1846d489e18513d4306b70e257a21edb56e82325de0139af91dd2176975029bf\"\n",
    "        },\n",
    "        \"series_ids\": [\"SF61745\",\"SF331451\",\"SF43783\",\"SF43878\",\"SF111916\"],\n",
    "        \"series_map\": {\n",
    "            \"SF61745\": \"Target rate 1/\",\n",
    "            \"SF331451\": \"Overnight TIIE funding rate 2/\",\n",
    "            \"SF43783\": \"28 day TIIE 3/\",\n",
    "            \"SF43878\": \"91 day TIIE 3/\",\n",
    "            \"SF111916\": \"182 day TIIE 3/\"\n",
    "        }\n",
    "    },\n",
    "    \"BoC\": {\n",
    "        \"fetcher\": fetch_boc,\n",
    "        \"url\": \"https://www.bankofcanada.ca/valet/observations\",\n",
    "        \"series_ids\": [\"V39079\",\"CL.CDN.MOST.1DL\",\"V39078\",\"V80691310\",\"V122530\"],\n",
    "        \"series_map\": {\n",
    "            \"V39079\": \"Target for the overnight rate\",\n",
    "            \"CL.CDN.MOST.1DL\": \"Overnight money market financing rate1\",\n",
    "            \"V39078\": \"Bank rate - Daily\",\n",
    "            \"V80691310\": \"Bank rate - Weekly\",\n",
    "            \"V122530\": \"Bank rate - Monthly\"\n",
    "        }\n",
    "    },\n",
    "    \"RBA\": {\n",
    "        \"fetcher\": fetch_rba,\n",
    "        \"url\": \"https://www.rba.gov.au/statistics/tables/xls/f01d.xlsx\"\n",
    "    },\n",
    "    \"BCRA\": {\n",
    "        \"fetcher\": fetch_bcra,\n",
    "        \"url\": \"https://www.bcra.gob.ar/PublicacionesEstadisticas/Principales_variables_i.asp\"\n",
    "    },\n",
    "    \"BOJ\": {\n",
    "        \"fetcher\": fetch_boj,\n",
    "        \"url\": \"https://www3.boj.or.jp/market/en/stat\"\n",
    "    },\n",
    "    \"NYCFED\": {\n",
    "        \"fetcher\": fetch_nyfed,\n",
    "        \"url\": \"https://markets.newyorkfed.org/read\",\n",
    "        \"headers\": {\n",
    "            \"sort\": \"postDt:-1,'data.closeTm':-1\",\n",
    "            \"productCode\": 70,     # repo operations\n",
    "            \"eventCodes\": 730,     # event code for operations\n",
    "            \"format\": \"csv\"        # NY Fed supports csv or xls\n",
    "        }\n",
    "    },\n",
    "    \"CBOE\": {\n",
    "        \"fetcher\": fetch_cboe,\n",
    "        \"url\": \"https://cdn.cboe.com/api/global/us_indices/daily_prices/OVX_History.csv\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def run_pipeline(days=5, outfile=\"central_banks_config_2.xlsx\"):\n",
    "    end = datetime.today()\n",
    "    start = end - timedelta(days=days)\n",
    "\n",
    "    with pd.ExcelWriter(outfile) as writer:\n",
    "        for name, cfg in CONFIG.items():\n",
    "            fetcher = cfg[\"fetcher\"]\n",
    "\n",
    "            try:\n",
    "                if name in [\"Banxico\", \"BoC\"]:\n",
    "                    df = fetcher(cfg, start.strftime(\"%Y-%m-%d\"), end.strftime(\"%Y-%m-%d\"))\n",
    "                if name in [\"BOJ\"]:\n",
    "                    df = fetcher(cfg, start.strftime(\"%y%m%d\"), end.strftime(\"%y%m%d\"))\n",
    "                elif name in [\"CBOE\"]:\n",
    "                    df = fetcher(cfg, start, end)\n",
    "                elif name in [\"NYCFED\"]:\n",
    "                    df = fetcher(cfg, start.strftime(\"%Y-%m-%d\"), end.strftime(\"%Y-%m-%d\"))\n",
    "                else:\n",
    "                    df = fetcher(cfg, start, end)\n",
    "\n",
    "                if df is not None and not df.empty:\n",
    "                    df.to_excel(writer, sheet_name=name, index=not name in [\"RBA\", \"BCRA\"])\n",
    "                else:\n",
    "                    print(f\"{name}: No data returned\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {name}: {e}\")\n",
    "\n",
    "    print(f\"Data saved to {outfile}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline(days=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": \"Mozilla/5.0\"})\n",
    "\n",
    "\n",
    "# ---- Shared Pandas Helpers ----\n",
    "def normalize_columns_to_dates(df):\n",
    "    \"\"\"Convert datetime-like columns to mm-dd-YYYY strings.\"\"\"\n",
    "    df.columns = [\n",
    "        c.strftime(\"%m-%d-%Y\") if isinstance(c, pd.Timestamp) else c\n",
    "        for c in df.columns\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "def ensure_full_date_range(df, start, end):\n",
    "    \"\"\"Ensure dataframe has full date coverage, fill missing dates with NaN.\"\"\"\n",
    "    full_range = pd.date_range(start=start, end=end, freq=\"D\")\n",
    "    df = df.reindex(columns=full_range)\n",
    "    return normalize_columns_to_dates(df)\n",
    "\n",
    "# ---- Fetchers ----\n",
    "def fetch_rba(cfg, start=None, end=None):\n",
    "    r = session.get(cfg[\"url\"], timeout=15)\n",
    "    r.raise_for_status()\n",
    "    df = pd.read_excel(BytesIO(r.content))\n",
    "\n",
    "    df.columns = df.iloc[1, :]\n",
    "    df = df.iloc[-5:, :].T.reset_index()\n",
    "    df.columns = df.iloc[0, :]\n",
    "    df = df.drop(df.index[0])\n",
    "\n",
    "    return normalize_columns_to_dates(df)\n",
    "\n",
    "def fetch_bcra(cfg, start=None, end=None):\n",
    "    r = session.get(cfg[\"url\"], timeout=15, verify=False)\n",
    "    r.raise_for_status()\n",
    "    df = pd.read_html(r.text)[0]\n",
    "\n",
    "    today = datetime.today()\n",
    "    date_range = pd.date_range(end=today, periods=5)   # last 5 days\n",
    "\n",
    "    df.columns = [\"Header\", \"Date\", \"Value\"]\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "    reshaped = df.pivot_table(index=\"Header\", columns=\"Date\", values=\"Value\", aggfunc=\"first\")\n",
    "    reshaped = reshaped.reindex(columns=date_range)\n",
    "    reshaped = normalize_columns_to_dates(reshaped)\n",
    "    return reshaped.reset_index()\n",
    "\n",
    "def fetch_banxico(cfg, start, end):\n",
    "    url = f\"{cfg['url']}/{','.join(cfg['series_ids'])}/datos/{start}/{end}\"\n",
    "    r = session.get(url, headers=cfg[\"headers\"], timeout=15)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    records = {}\n",
    "    for s in data['bmx']['series']:\n",
    "        sid = s['idSerie']\n",
    "        rec = {d['fecha']: d['dato'] for d in s['datos']}\n",
    "        records[sid] = rec\n",
    "\n",
    "    df = pd.DataFrame.from_dict(records, orient=\"index\")\n",
    "    df.columns = pd.to_datetime(df.columns, dayfirst=True)\n",
    "    df.index = df.index.map(lambda x: cfg[\"series_map\"].get(x, x))\n",
    "\n",
    "    return normalize_columns_to_dates(df.sort_index(axis=1))\n",
    "\n",
    "def fetch_boc(cfg, start, end):\n",
    "    url = f\"{cfg['url']}/{','.join(cfg['series_ids'])}/json?start_date={start}&end_date={end}\"\n",
    "    r = session.get(url, timeout=15)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    records = {}\n",
    "    for row in data[\"observations\"]:\n",
    "        date = row[\"d\"]\n",
    "        for sid in cfg[\"series_ids\"]:\n",
    "            records.setdefault(sid, {})[date] = row.get(sid, {}).get(\"v\")\n",
    "\n",
    "    df = pd.DataFrame.from_dict(records, orient=\"index\")\n",
    "    df.columns = pd.to_datetime(df.columns)\n",
    "    df = ensure_full_date_range(df, start, end)\n",
    "    df.index = df.index.map(lambda x: cfg[\"series_map\"].get(x, x))\n",
    "\n",
    "    return df.sort_index(axis=1)\n",
    "\n",
    "def fetch_boj(cfg, start, end):\n",
    "    dates = pd.date_range(start=datetime.strptime(start, \"%y%m%d\"), end=datetime.strptime(end, \"%y%m%d\"))\n",
    "    records = {}\n",
    "\n",
    "    for date in dates:\n",
    "        url = f\"{cfg['url']}/md{date.strftime('%y%m%d')}.htm\"\n",
    "        try:\n",
    "            r = session.get(url, timeout=15)\n",
    "            if r.status_code != 200:continue\n",
    "        except Exception:continue\n",
    "\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        for li in soup.find_all(\"li\"):\n",
    "            text = li.get_text(strip=True)\n",
    "            text = re.sub(r\"[\\[\\%]+\",\"\",text,re.IGNORECASE)\n",
    "            parts = text.split(\"]\")\n",
    "            if len(parts) < 2:continue\n",
    "            key,val = parts\n",
    "            # print(f\"{key}:{val}\")\n",
    "            series_name = f\"Call Rate {key}\"\n",
    "            records.setdefault(series_name, {})[date] = val\n",
    "\n",
    "    out = pd.DataFrame.from_dict(records, orient=\"index\")\n",
    "    out = out.reindex(columns=dates)\n",
    "    return normalize_columns_to_dates(out)\n",
    "\n",
    "def fetch_nyfed(cfg, start, end):\n",
    "    url = (\n",
    "        f\"{cfg['url']}?startDt={start}&endDt={end}\"\n",
    "        f\"&sort={cfg['headers']['sort']}\"\n",
    "        f\"&productCode={cfg['headers']['productCode']}\"\n",
    "        f\"&eventCodes={cfg['headers']['eventCodes']}\"\n",
    "        f\"&format={cfg['headers']['format']}\"\n",
    "    )\n",
    "    r = session.get(url, timeout=15)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    if cfg[\"headers\"][\"format\"] == \"csv\":\n",
    "        df = pd.read_csv(BytesIO(r.content))\n",
    "    else:\n",
    "        df = pd.read_excel(BytesIO(r.content))\n",
    "\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def fetch_cboe(cfg, start=None, end=None, days=5):\n",
    "    r = session.get(cfg[\"url\"], timeout=15, verify=False)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    df = pd.read_csv(BytesIO(r.content))\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], errors=\"coerce\")\n",
    "    df = df.iloc[-days:, :]\n",
    "    start_dt = pd.to_datetime(start)\n",
    "    end_dt = pd.to_datetime(end)\n",
    "    full_range = pd.date_range(start=start_dt, end=end_dt, freq=\"D\")\n",
    "    df = df.set_index(\"DATE\").reindex(full_range)\n",
    "    wide = pd.DataFrame([df[\"OVX\"].tolist()], index=[\"OVX Index\"], columns=full_range)\n",
    "    return normalize_columns_to_dates(wide)\n",
    "\n",
    "CONFIG = {\n",
    "    \"Banxico\": {\n",
    "        \"fetcher\": fetch_banxico,\n",
    "        \"url\": \"https://www.banxico.org.mx/SieAPIRest/service/v1/series\",\n",
    "        \"headers\": {\n",
    "            \"Bmx-Token\": \"1846d489e18513d4306b70e257a21edb56e82325de0139af91dd2176975029bf\"\n",
    "        },\n",
    "        \"series_ids\": [\"SF61745\",\"SF331451\",\"SF43783\",\"SF43878\",\"SF111916\"],\n",
    "        \"series_map\": {\n",
    "            \"SF61745\": \"Target rate 1/\",\n",
    "            \"SF331451\": \"Overnight TIIE funding rate 2/\",\n",
    "            \"SF43783\": \"28 day TIIE 3/\",\n",
    "            \"SF43878\": \"91 day TIIE 3/\",\n",
    "            \"SF111916\": \"182 day TIIE 3/\"\n",
    "        }\n",
    "    },\n",
    "    \"BoC\": {\n",
    "        \"fetcher\": fetch_boc,\n",
    "        \"url\": \"https://www.bankofcanada.ca/valet/observations\",\n",
    "        \"series_ids\": [\"V39079\",\"CL.CDN.MOST.1DL\",\"V39078\",\"V80691310\",\"V122530\"],\n",
    "        \"series_map\": {\n",
    "            \"V39079\": \"Target for the overnight rate\",\n",
    "            \"CL.CDN.MOST.1DL\": \"Overnight money market financing rate1\",\n",
    "            \"V39078\": \"Bank rate - Daily\",\n",
    "            \"V80691310\": \"Bank rate - Weekly\",\n",
    "            \"V122530\": \"Bank rate - Monthly\"\n",
    "        }\n",
    "    },\n",
    "    \"RBA\": {\n",
    "        \"fetcher\": fetch_rba,\n",
    "        \"url\": \"https://www.rba.gov.au/statistics/tables/xls/f01d.xlsx\"\n",
    "    },\n",
    "    \"BCRA\": {\n",
    "        \"fetcher\": fetch_bcra,\n",
    "        \"url\": \"https://www.bcra.gob.ar/PublicacionesEstadisticas/Principales_variables_i.asp\"\n",
    "    },\n",
    "    \"BOJ\": {\n",
    "        \"fetcher\": fetch_boj,\n",
    "        \"url\": \"https://www3.boj.or.jp/market/en/stat\"\n",
    "    },\n",
    "    \"NYCFED\": {\n",
    "        \"fetcher\": fetch_nyfed,\n",
    "        \"url\": \"https://markets.newyorkfed.org/read\",\n",
    "        \"headers\": {\n",
    "            \"sort\": \"postDt:-1,'data.closeTm':-1\",\n",
    "            \"productCode\": 70,     # repo operations\n",
    "            \"eventCodes\": 730,     # event code for operations\n",
    "            \"format\": \"csv\"        # NY Fed supports csv or xls\n",
    "        }\n",
    "    },\n",
    "    \"CBOE\": {\n",
    "        \"fetcher\": fetch_cboe,\n",
    "        \"url\": \"https://cdn.cboe.com/api/global/us_indices/daily_prices/OVX_History.csv\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def run_pipeline(days=5, outfile=\"central_banks_config_2.xlsx\"):\n",
    "    end = datetime.today()\n",
    "    start = end - timedelta(days=days)\n",
    "    \n",
    "    # print(start.strftime(\"%Y-%m-%d\"), end.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    with pd.ExcelWriter(outfile) as writer:\n",
    "        for name, cfg in CONFIG.items():\n",
    "            fetcher = cfg[\"fetcher\"]\n",
    "            try:\n",
    "                # if name in [\"Banxico\", \"BoC\"]:\n",
    "                #     df = fetcher(cfg, start.strftime(\"%Y-%m-%d\"), end.strftime(\"%Y-%m-%d\"))\n",
    "                # if name in [\"BOJ\"]:\n",
    "                #     df = fetcher(cfg, start.strftime(\"%y%m%d\"), end.strftime(\"%y%m%d\"))\n",
    "                # elif name in [\"CBOE\"]:\n",
    "                #     df = fetcher(cfg, start, end)\n",
    "                # elif name in [\"NYCFED\"]:\n",
    "                #     df = fetcher(cfg, start.strftime(\"%Y-%m-%d\"), end.strftime(\"%Y-%m-%d\"))\n",
    "                # else:\n",
    "                if name in ['BCRA','RBA']:\n",
    "                    df = fetcher(cfg, start, end) #BCRA RBA\n",
    "\n",
    "                if df is not None and not df.empty:\n",
    "                    df.to_excel(writer, sheet_name=name)\n",
    "                else:\n",
    "                    print(f\"{name}: No data returned\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {name}: {e}\")\n",
    "\n",
    "    print(f\"Data saved to {outfile}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline(days=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO,StringIO\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": \"Mozilla/5.0\"})\n",
    "\n",
    "def fetch_rba(): \n",
    "    url = \"https://www.rba.gov.au/statistics/tables/xls/f01d.xlsx\" \n",
    "    r = session.get(url, timeout=15) \n",
    "    r.raise_for_status() \n",
    "    df = pd.read_excel(BytesIO(r.content)) \n",
    "    df.columns = df.iloc[1, :]\n",
    "    df = df.iloc[-5:, :].T.reset_index()\n",
    "    df.columns = df.iloc[0, :]\n",
    "    df = df.drop(df.index[0])\n",
    "    df.columns = [(lambda c: pd.to_datetime(c, errors=\"ignore\"))(c) for c in df.columns]\n",
    "    df.columns = [c.strftime(\"%m-%d-%Y\") if isinstance(c, pd.Timestamp) else c for c in df.columns]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fetch_bcra():\n",
    "    url = \"https://www.bcra.gob.ar/PublicacionesEstadisticas/Principales_variables_i.asp\"\n",
    "    r = session.get(url, timeout=15, verify=False)\n",
    "    r.raise_for_status()\n",
    "    df = pd.read_html(r.text)[0]\n",
    "    \n",
    "    today = datetime.today().strftime(\"%m/%d/%Y\")\n",
    "    date_range = pd.date_range(end=today, periods=5)   # datetime index\n",
    "\n",
    "    df.columns = [\"Header\",\"Date\",\"Value\"]\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "    reshaped = (df.pivot_table(index=\"Header\", columns=\"Date\", values=\"Value\", aggfunc=\"first\"))\n",
    "    reshaped = reshaped.reindex(columns=date_range)\n",
    "    reshaped.columns = [d.strftime(\"%m-%d-%Y\") for d in reshaped.columns]\n",
    "    reshaped = reshaped.reset_index()\n",
    "    return reshaped\n",
    "\n",
    "def fetch_banxico(token, series_ids, start, end): \n",
    "    #mapper\n",
    "    series_map = {\n",
    "        \"SF61745\": \"Target rate 1/\",\n",
    "        \"SF331451\": \"Overnight TIIE funding rate 2/\",\n",
    "        \"SF43783\": \"28 day TIIE 3/\",\n",
    "        \"SF43878\": \"91 day TIIE 3/\",\n",
    "        \"SF111916\": \"182 day TIIE 3/\"\n",
    "    }\n",
    "    \n",
    "    #api call\n",
    "    url = f\"https://www.banxico.org.mx/SieAPIRest/service/v1/series/{','.join(series_ids)}/datos/{start}/{end}\"\n",
    "    headers = {\"Bmx-Token\": token}\n",
    "    r = session.get(url, headers=headers, timeout=15)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    records = {}\n",
    "    for s in data['bmx']['series']:\n",
    "        sid = s['idSerie']\n",
    "        rec = {d['fecha']: d['dato'] for d in s['datos']}\n",
    "        records[sid] = rec\n",
    "    df = pd.DataFrame.from_dict(records, orient=\"index\")\n",
    "    df.columns = pd.to_datetime(df.columns, dayfirst=True)\n",
    "    \n",
    "    df.index = df.index.map(lambda x: series_map.get(x, x))\n",
    "    # print(df)\n",
    "    df.columns = [d.strftime(\"%m-%d-%Y\") for d in df.columns]\n",
    "    \n",
    "    return df.sort_index(axis=1)\n",
    "\n",
    "def fetch_boc(series_ids, start, end):\n",
    "    series_map = {\n",
    "        \"V39079\": \"Target for the overnight rate\",\n",
    "        \"CL.CDN.MOST.1DL\": \"Overnight money market financing rate1\",\n",
    "        \"V39078\": \"Bank rate - Daily\",\n",
    "        \"V80691310\": \"Bank rate - Weekly\",\n",
    "        \"V122530\": \"Bank rate - Monthly\"\n",
    "    }\n",
    "    \n",
    "    url = f\"https://www.bankofcanada.ca/valet/observations/{','.join(series_ids)}/json?start_date={start}&end_date={end}\"\n",
    "    r = session.get(url, timeout=15)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    records = {}\n",
    "    for row in data[\"observations\"]:\n",
    "        date = row[\"d\"]\n",
    "        for sid in series_ids:\n",
    "            records.setdefault(sid, {})[date] = row.get(sid, {}).get(\"v\")\n",
    "\n",
    "    df = pd.DataFrame.from_dict(records, orient=\"index\")\n",
    "    # make sure column labels are datetime\n",
    "    df.columns = pd.to_datetime(df.columns)\n",
    "    full_range = pd.date_range(start=start, end=end, freq=\"D\")\n",
    "    df = df.reindex(columns=full_range)\n",
    "    df.columns = [d.strftime(\"%m-%d-%Y\") for d in df.columns]\n",
    "    df.index = df.index.map(lambda x: series_map.get(x, x))\n",
    "\n",
    "    return df.sort_index(axis=1)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(\"central_banks_1.xlsx\") as writer:\n",
    "    token = \"1846d489e18513d4306b70e257a21edb56e82325de0139af91dd2176975029bf\"\n",
    "    fetch_banxico(token, [\"SF61745\",\"SF331451\",\"SF43783\",\"SF43878\",\"SF111916\"], \"2025-09-25\", \"2025-09-29\")\\\n",
    "        .to_excel(writer, sheet_name=\"Banxico\")\n",
    "    fetch_boc([\"V39079\",\"CL.CDN.MOST.1DL\",\"V39078\",\"V80691310\",\"V122530\"], \"2025-09-25\", \"2025-09-29\")\\\n",
    "        .to_excel(writer, sheet_name=\"BoC\")\n",
    "    fetch_rba().to_excel(writer, sheet_name=\"RBA\", index = False)\n",
    "    fetch_bcra().to_excel(writer, sheet_name=\"BCRA\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
